{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools in LlamaIndex\n",
    "\n",
    "Defining a clear set of  tools is crucial to performance. Clear tool interfaces are easier for LLMs to use, similar to software API interface for human engineers.\n",
    "\n",
    "`LlamaIndex` has 4 main types of tools: Function Tools, Search Engine, ToolSpecs, Utility Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Tool:\n",
    "Provides a simple way to wrap any Python function and make it available to any agent -- could be synchronous, or async, with optional `name` and `description`. The `name` and `description` are important as they help the agent understand when and how to use the tool effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting weather for New York\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ToolOutput(content='The weather in New York is sunny.', tool_name='my_weather_tool', raw_input={'args': ('New York',), 'kwargs': {}}, raw_output='The weather in New York is sunny.', is_error=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Useful for getting the weather for a given location.\"\"\"\n",
    "    print(f'Getting weather for {location}')\n",
    "    return f'The weather in {location} is sunny.'\n",
    "\n",
    "tool = FunctionTool.from_defaults(\n",
    "    get_weather, \n",
    "    name='my_weather_tool',\n",
    "    description=\"Useful for getting the weather for a given location.\",\n",
    ")\n",
    "\n",
    "tool.call(\"New York\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Engine Tool\n",
    "\n",
    "The Query Engine we created in `RAGUsingQueryEngine.ipynb` can easily be transformed into a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolOutput(content='The impact of AI on the future of work and society is a multifaceted topic that encompasses various aspects, including changes in job dynamics, the need for new skills, and the potential for increased inequality. Research indicates that while AI can enhance productivity and create new job opportunities, it may also lead to job displacement in certain sectors. Additionally, the integration of AI into workplaces raises ethical considerations regarding privacy, bias, and decision-making processes. As AI continues to evolve, it is crucial to address these challenges through policies that promote equity and inclusion, ensuring that all communities benefit from technological advancements.', tool_name='Alfreds Persona Query Engine', raw_input={'input': 'Responds about research on the impact of AI on the future of work and society?'}, raw_output=Response(response='The impact of AI on the future of work and society is a multifaceted topic that encompasses various aspects, including changes in job dynamics, the need for new skills, and the potential for increased inequality. Research indicates that while AI can enhance productivity and create new job opportunities, it may also lead to job displacement in certain sectors. Additionally, the integration of AI into workplaces raises ethical considerations regarding privacy, bias, and decision-making processes. As AI continues to evolve, it is crucial to address these challenges through policies that promote equity and inclusion, ensuring that all communities benefit from technological advancements.', source_nodes=[NodeWithScore(node=TextNode(id_='4c8b8c76-0bf0-4057-8c9e-7d2e554dbf5b', embedding=None, metadata={'file_path': '/media/chaitanya/8c668157-d88f-4711-8236-2a53e5225d1d/Work/HuggingFace-ai-agents-course/Unit2/2.2-llamaindex/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-04-29', 'last_modified_date': '2025-04-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8aacb0e4-e9cb-4b03-865c-3e3b660772a9', node_type='4', metadata={'file_path': '/media/chaitanya/8c668157-d88f-4711-8236-2a53e5225d1d/Work/HuggingFace-ai-agents-course/Unit2/2.2-llamaindex/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-04-29', 'last_modified_date': '2025-04-29'}, hash='24b8ddfb8f41c097ba420caa11d60567e6cf83bc95027b777a3ba3653c3a60a6')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A social justice educator or activist focused on diversity, equity, and inclusion, likely working with families and communities to promote empathy and understanding of intersectional identity and oppression.', mimetype='text/plain', start_char_idx=0, end_char_idx=207, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4286035190518414), NodeWithScore(node=TextNode(id_='c6a330a1-ea5e-4a4a-aabc-81cc2b64524c', embedding=None, metadata={'file_path': '/media/chaitanya/8c668157-d88f-4711-8236-2a53e5225d1d/Work/HuggingFace-ai-agents-course/Unit2/2.2-llamaindex/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-04-28', 'last_modified_date': '2025-04-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ccbfc6c1-c480-4464-be3b-645f08e9fe8d', node_type='4', metadata={'file_path': '/media/chaitanya/8c668157-d88f-4711-8236-2a53e5225d1d/Work/HuggingFace-ai-agents-course/Unit2/2.2-llamaindex/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-04-28', 'last_modified_date': '2025-04-28'}, hash='fca1d6076cc39c26775a6851f22f1358f7a67540a940ee34d9c66b92b6f28076')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A social justice educator or activist focused on diversity, equity, and inclusion, likely working with families and communities to promote empathy and understanding of intersectional identity and oppression.', mimetype='text/plain', start_char_idx=0, end_char_idx=207, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4286035190518414)], metadata={'4c8b8c76-0bf0-4057-8c9e-7d2e554dbf5b': {'file_path': '/media/chaitanya/8c668157-d88f-4711-8236-2a53e5225d1d/Work/HuggingFace-ai-agents-course/Unit2/2.2-llamaindex/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-04-29', 'last_modified_date': '2025-04-29'}, 'c6a330a1-ea5e-4a4a-aabc-81cc2b64524c': {'file_path': '/media/chaitanya/8c668157-d88f-4711-8236-2a53e5225d1d/Work/HuggingFace-ai-agents-course/Unit2/2.2-llamaindex/data/persona_10.txt', 'file_name': 'persona_10.txt', 'file_type': 'text/plain', 'file_size': 207, 'creation_date': '2025-04-28', 'last_modified_date': '2025-04-28'}}), is_error=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()   # load OPENAI API key into memory\n",
    "\n",
    "embed_model = HuggingFaceEmbedding('BAAI/bge-small-en-v1.5')\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection('alfred')\n",
    "vector_store = ChromaVectorStore(chroma_collection = chroma_collection)\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    embed_model = embed_model\n",
    ")\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\") \n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "tool = QueryEngineTool.from_defaults(\n",
    "    query_engine, name = 'Alfreds Persona Query Engine', description = 'A persona of a helpful assistant'\n",
    ")\n",
    "\n",
    "await tool.acall(\n",
    "    \"Responds about research on the impact of AI on the future of work and society?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToolSpecs\n",
    "\n",
    "`ToolSpecs` are collections of tools that work together harmoniously -- like a professional toolkit. For instance, an accounting agent's `ToolSpec` might elegantly integrate spreadsheet capabilities, email functionality, and calculation tools to handle financial tasks with precision and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('load_data',\n",
       "  \"load_data() -> List[llama_index.core.schema.Document]\\nLoad emails from the user's account.\"),\n",
       " ('search_messages',\n",
       "  \"search_messages(query: str, max_results: Optional[int] = None)\\nSearches email messages given a query string and the maximum number\\n        of results requested by the user\\n           Returns: List of relevant message objects up to the maximum number of results.\\n\\n        Args:\\n            query[str]: The user's query\\n            max_results (Optional[int]): The maximum number of search results\\n            to return.\\n        \"),\n",
       " ('create_draft',\n",
       "  \"create_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None) -> str\\nCreate and insert a draft email.\\n           Print the returned draft's message and id.\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            to (Optional[str]): The email addresses to send the message to\\n            subject (Optional[str]): The subject for the event\\n            message (Optional[str]): The message for the event\\n        \"),\n",
       " ('update_draft',\n",
       "  \"update_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None, draft_id: str = None) -> str\\nUpdate a draft email.\\n           Print the returned draft's message and id.\\n           This function is required to be passed a draft_id that is obtained when creating messages\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            to (Optional[str]): The email addresses to send the message to\\n            subject (Optional[str]): The subject for the event\\n            message (Optional[str]): The message for the event\\n            draft_id (str): the id of the draft to be updated\\n        \"),\n",
       " ('get_draft',\n",
       "  \"get_draft(draft_id: str = None) -> str\\nGet a draft email.\\n           Print the returned draft's message and id.\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            draft_id (str): the id of the draft to be updated\\n        \"),\n",
       " ('send_draft',\n",
       "  \"send_draft(draft_id: str = None) -> str\\nSends a draft email.\\n           Print the returned draft's message and id.\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            draft_id (str): the id of the draft to be updated\\n        \")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.tools.google import GmailToolSpec\n",
    "\n",
    "tool_spec = GmailToolSpec()\n",
    "tool_spec_list = tool_spec.to_tool_list()\n",
    "\n",
    "# view metadata of each tool, for a more detailed view\n",
    "[(tool.metadata.name, tool.metadata.description) for tool in tool_spec_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Context Protocol (MCP) in LlamaIndex\n",
    "\n",
    "LlamaIndex allows using MCP through a [ToolSpec on the LlamaHub](https://llamahub.ai/l/tools/llama-index-tools-mcp?from=)You can simply run an MCP server and start using it as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "# assume MCP server running on 127.0.0.1:8000\n",
    "mcp_client = BasicMCPClient('http://127.0.0.1:8000/sse')\n",
    "mcp_tool = McpToolSpec(client=mcp_client)\n",
    "\n",
    "# sync:\n",
    "# tools = mcp_tool.to_tool_list()\n",
    "\n",
    "# async:\n",
    "tools = await mcp_tool.to_tool_list_async()\n",
    "\n",
    "## Then use `tools` in your agent as below\n",
    "# from llama_index.core.agent.workflow import FunctionAgent\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# agent = FunctionAgent(\n",
    "#     name=\"Agent\",\n",
    "#     description=\"Some description\",\n",
    "#     llm=OpenAI(model=\"gpt-4o\"),\n",
    "#     tools=tools,\n",
    "#     system_prompt=\"You are a helpful assistant.\",\n",
    "# )\n",
    "\n",
    "# resp = await agent.run(\"What is the weather in Tokyo?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Tools\n",
    "In addition to the above, there are also Utility Tools that can be used to perform common tasks. For instance, \n",
    "- `OnDemandToolLoader` turns any existing `LlamaIndex` data loader (`BaseReader` class) into a tool that an agent can use. The tool can be called with all the parameters needed to trigger load_data from the data loader, along with a natural language query string. During execution, we first load data from the data loader, index it (for instance with a vector store), and then query it ‘on-demand’. All three of these steps happen in a single tool call.\n",
    "- `LoadAndSearchToolSpec` takes in any existing Tool as input. As a tool spec, it implements `to_tool_list` and when that function is called, two tools are returned: one for loading data and one for searching the loaded data. The load Tool execution would call the underlying Tool, and the search Tool execution would take in a query string as input and call the underlying index.\n",
    "\n",
    "\n",
    "**See LlamaHub for more**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
