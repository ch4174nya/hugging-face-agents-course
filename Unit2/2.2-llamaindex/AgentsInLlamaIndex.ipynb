{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents in LlamaIndex\n",
    "\n",
    "> Unit 1: An agent is a system that leverages an AI model to interact with its environment to achieve a user-defined objective. It combines reasoning, planning and action execution (often via external tools) to fulfil tasks.\n",
    "\n",
    "`LlamaIndex` supports 3 main types of reasoning agents:\n",
    "- Function Calling Agents: These work with AI models that can call specific functions.\n",
    "- ReAct Agents: These work with any AI model that does chat or text endponit and deal with complex reasoning tasks.\n",
    "- Advanced Custom Agents: use more complex methods to deal with complex workflows and tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "# define a simple tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divide two numbers\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# ccreate agent\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[subtract, multiply, divide, add],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called Tool: add {'a': 2, 'b': 2} => 4\n",
      "\n",
      "Called Tool: multiply {'a': 4, 'b': 2} => 8\n",
      "The result of (2 + 2) * 2 is 8."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='The result of (2 + 2) * 2 is 8.')]), tool_calls=[ToolCallResult(tool_name='add', tool_kwargs={'a': 2, 'b': 2}, tool_id='call_GfVMyUrONBYNM4FefcCtglhH', tool_output=ToolOutput(content='4', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 2}}, raw_output=4, is_error=False), return_direct=False), ToolCallResult(tool_name='multiply', tool_kwargs={'a': 4, 'b': 2}, tool_id='call_3TZWXlu7U4yQSlsroiWMoGKA', tool_output=ToolOutput(content='8', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 4, 'b': 2}}, raw_output=8, is_error=False), return_direct=False)], raw={'id': 'chatcmpl-BRh3KiAEG8vdimbU0jSwCFe4CgASr', 'choices': [{'delta': {'content': None, 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None}], 'created': 1745940050, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion.chunk', 'service_tier': 'default', 'system_fingerprint': 'fp_0392822090', 'usage': None}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = agent.run('What is (2+2) * 2 ?')\n",
    "\n",
    "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print('')\n",
    "        print(f'Called Tool: {ev.tool_name} {ev.tool_kwargs} => {ev.tool_output}')\n",
    "    elif isinstance(ev, AgentStream):   # shows thought process/reasoning steps\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents are stateless by default\n",
    "So we need to add memory to the agent, and this is done through a `Context` object. This comes handy, for instance, in a chatbot app where the agent needs to remember previous interactions (or a task manager tracking progress over time)\n",
    "\n",
    "Note: didn't quite work in the example below :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Hello, Bob! How can I assist you today?\n",
      "Response: Your name is Bob.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(agent)\n",
    "\n",
    "response = await agent.run('My name is bob', ctx=ctx)\n",
    "print(f'Response: {response}')\n",
    "response = await agent.run('What is my name again?', ctx=ctx)\n",
    "print(f'Response: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating RAG Agents with QueryEngineTools\n",
    "\n",
    "We can pass various tools to Alfred to help him answer questions. However, instead of answering the question on top of documents automatically, Alfred can decide to use any other tool or flow to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Create vector store\n",
    "db = chromadb.PersistentClient('./alfred_chroma_db')\n",
    "chroma_collection = db.get_or_create_collection('alfred')\n",
    "vector_store = ChromaVectorStore(chroma_collection)\n",
    "\n",
    "# Create a query engine\n",
    "embed_model = HuggingFaceEmbedding('BAAI/bge-small-en-v1.5')\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llm = OpenAI(model='gpt-4o-mini')\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, \n",
    "    embed_model=embed_model)\n",
    "\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "query_engine_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name='personas',\n",
    "    description='Query descriptions for various personas',\n",
    "    return_direct=False\n",
    ")\n",
    "\n",
    "# Create a RAG Agent\n",
    "query_engine_agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[query_engine_tool],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that has access to a database containing persona descriptions.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called Tool: personas {'input': 'traveler'} => The information provided does not relate to a traveler. It focuses on an environmental historian or urban planner with an emphasis on ecological conservation and sustainability.\n",
      "\n",
      "Called Tool: personas {'input': 'travel'} => Travel can encompass various aspects, including exploring new places, understanding different cultures, and experiencing nature. For someone focused on ecological conservation and sustainability, travel might involve visiting natural reserves, studying urban planning in different regions, or participating in environmental initiatives. This type of travel can provide valuable insights into sustainable practices and the impact of urban development on the environment.\n",
      "It seems that the database does not have specific persona descriptions for a \"traveler.\" Instead, it provides insights related to travel in the context of ecological conservation and sustainability. This perspective emphasizes exploring new places, understanding different cultures, and experiencing nature, particularly through the lens of environmental initiatives and urban planning. \n",
      "\n",
      "If you have a more specific aspect of travel or a different term in mind, please let me know!\n",
      "Response: It seems that the database does not have specific persona descriptions for a \"traveler.\" Instead, it provides insights related to travel in the context of ecological conservation and sustainability. This perspective emphasizes exploring new places, understanding different cultures, and experiencing nature, particularly through the lens of environmental initiatives and urban planning. \n",
      "\n",
      "If you have a more specific aspect of travel or a different term in mind, please let me know!\n"
     ]
    }
   ],
   "source": [
    "handler = query_engine_agent.run(\n",
    "    \"Search the database for 'traveler' and return some persona descriptions.\"\n",
    ")\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, AgentStream):\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "    elif isinstance(ev, ToolCallResult):\n",
    "        print(f\"\\nCalled Tool: {ev.tool_name} {ev.tool_kwargs} => {ev.tool_output}\")\n",
    "\n",
    "resp = await handler\n",
    "print(f\"\\nResponse: {resp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating multi-agent systems\n",
    "Passing multiple agents to the `AgentWorkflow` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentWorkflow,\n",
    "    ReActAgent\n",
    ")\n",
    "\n",
    "# define some tools:\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "# Create agent configs\n",
    "# NOTE: we can use FunctionAgent or ReActAgent here.\n",
    "# FunctionAgent works for LLMs with a function calling API.\n",
    "# ReActAgent works for any LLM.\n",
    "calculator_agent = ReActAgent(\n",
    "    name='calculator',\n",
    "    description='Performs basic arithmetic operations',\n",
    "    system_prompt=\"You are a calculator assistant. Use your tools for any math operation.\",\n",
    "    tools = [add, subtract],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "query_agent = ReActAgent(\n",
    "    name='info_lookup',\n",
    "    description='Looks up information about XYZ',\n",
    "    system_prompt=\"Use your tool to query a RAG system to answer information about XYZ\",\n",
    "    tools = [query_engine_tool],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "agent = AgentWorkflow(\n",
    "    agents= [calculator_agent, query_agent],\n",
    "    root_agent='calculator'\n",
    ")\n",
    "\n",
    "handler = agent.run(user_msg='can you add 5 and 3?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: add\n",
      "Action Input: {\"a\": 5, \"b\": 3}\n",
      "Called Tool: add, {'a': 5, 'b': 3} => 8\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The sum of 5 and 3 is 8.\n",
      "Response: The sum of 5 and 3 is 8.\n"
     ]
    }
   ],
   "source": [
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, AgentStream):\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "    elif isinstance(ev, ToolCallResult):\n",
    "        print(f'\\nCalled Tool: {ev.tool_name}, {ev.tool_kwargs} => {ev.tool_output}')\n",
    "\n",
    "resp = await handler\n",
    "print(f'\\nResponse: {resp}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
